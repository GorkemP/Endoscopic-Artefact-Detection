{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n"
     ]
    }
   ],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from google.colab.patches import cv2_imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metadata(name='ead_validation_1', thing_classes=['specularity', 'saturation', 'artifact', 'blur', 'contrast', 'bubbles', 'instrument', 'blood'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ead_dicts(img_dir):    \n",
    "    images_path = os.path.join(img_dir, '*.jpg')\n",
    "    images = glob.glob(images_path)\n",
    "    \n",
    "    dataset_dicts = []\n",
    "    \n",
    "    for idx, image_path in enumerate(images):\n",
    "        text_path= image_path.replace(\".jpg\", \".txt\")\n",
    "        \n",
    "        record = {}\n",
    "\n",
    "        height, width = cv2.imread(image_path).shape[:2]\n",
    "        \n",
    "        record[\"file_name\"] = image_path\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width        \n",
    "        \n",
    "        with open(text_path) as f:\n",
    "            contents = f.readlines()\n",
    "        \n",
    "        objs = []\n",
    "        for content in contents:\n",
    "            information = content.split(' ')\n",
    "            \n",
    "            obj = {\n",
    "                \"bbox\": [(float(information[1]) - float(information[3]) / 2)*width, \n",
    "                         (float(information[2]) - float(information[4]) / 2)*height, \n",
    "                         (float(information[1]) + float(information[3]) / 2)*width, \n",
    "                         (float(information[2]) + float(information[4]) / 2)*height],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                \"category_id\": int(information[0])\n",
    "            }\n",
    "            objs.append(obj)\n",
    "                        \n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)                        \n",
    "    return dataset_dicts\n",
    "\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "data_path = r'/home/ws2080/Desktop/codes/models/research/ead/data/'\n",
    "train_path = r'/home/ws2080/Desktop/data/training/train/'\n",
    "validation_path = r'/home/ws2080/Desktop/data/training/validation/'\n",
    "\n",
    "'''\n",
    "d= 'train'\n",
    "DatasetCatalog.register(\"ead_train_1\", lambda d=d: get_ead_dicts(train_path))\n",
    "MetadataCatalog.get(\"ead_train_1\").set(thing_classes=[\"specularity\", \"saturation\", \"artifact\", \"blur\", \"contrast\", \"bubbles\", \"instrument\", \"blood\"])\n",
    "\n",
    "'''\n",
    "\n",
    "d= 'validation'\n",
    "DatasetCatalog.register(\"ead_validation_1\", lambda d=d: get_ead_dicts(validation_path))\n",
    "MetadataCatalog.get(\"ead_validation_1\").set(thing_classes=[\"specularity\", \"saturation\", \"artifact\", \"blur\", \"contrast\", \"bubbles\", \"instrument\", \"blood\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n'0099999'\\n'0109999', \\n'0119999', \\n'0129999',\\n'0139999',\\n'0149999',\\n'0159999',\\n'0169999',\\n'0179999',\\n'0189999',\\n'0199999'\\n]\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'output'\n",
    "checkpoints = ['0009999',\n",
    "               '0019999',\n",
    "               '0029999',\n",
    "               '0039999',\n",
    "               '0049999',\n",
    "               '0059999',\n",
    "               '0069999',    \n",
    "               '0079999',               \n",
    "               '0089999']\n",
    "\n",
    "'''\n",
    "'0099999'\n",
    "'0109999', \n",
    "'0119999', \n",
    "'0129999',\n",
    "'0139999',\n",
    "'0149999',\n",
    "'0159999',\n",
    "'0169999',\n",
    "'0179999',\n",
    "'0189999',\n",
    "'0199999'\n",
    "]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "APs =[]\n",
    "AP50s = []\n",
    "AP75s = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/02 11:21:31 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'ead_validation_1'\n",
      "\u001b[32m[03/02 11:21:31 d2.data.datasets.coco]: \u001b[0mCached annotations in COCO format already exist: ./output/ead_validation_1_coco_format.json\n",
      "\u001b[32m[03/02 11:21:33 d2.data.build]: \u001b[0mDistribution of instances among all 8 categories:\n",
      "\u001b[36m|  category   | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:-----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| specularity | 1399         | saturation | 173          |  artifact  | 969          |\n",
      "|    blur     | 96           |  contrast  | 224          |  bubbles   | 622          |\n",
      "| instrument  | 62           |   blood    | 53           |            |              |\n",
      "|    total    | 3598         |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/02 11:21:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[03/02 11:21:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0314 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/02 11:21:38 d2.evaluation.evaluator]: \u001b[0mInference done 165/300. 0.0313 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/02 11:21:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.621450 (0.032615 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/02 11:21:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.031052 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/02 11:21:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/02 11:21:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[03/02 11:21:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=7.10s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.46s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.507\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.244\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.043\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.259\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.392\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.428\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.510\n",
      "\u001b[32m[03/02 11:21:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 27.120 | 50.744 | 24.391 | 4.277 | 14.898 | 34.590 |\n",
      "\u001b[32m[03/02 11:21:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 6.424  | saturation | 26.381 | artifact   | 19.127 |\n",
      "| blur        | 35.381 | contrast   | 40.945 | bubbles    | 9.953  |\n",
      "| instrument  | 68.800 | blood      | 9.946  |            |        |\n",
      "\u001b[32m[03/02 11:21:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[03/02 11:21:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0320 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/02 11:21:58 d2.evaluation.evaluator]: \u001b[0mInference done 166/300. 0.0307 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/02 11:22:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.516520 (0.032259 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/02 11:22:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.030666 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/02 11:22:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/02 11:22:03 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[03/02 11:22:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=6.45s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.44s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.266\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.504\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.243\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.072\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.412\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.495\n",
      "\u001b[32m[03/02 11:22:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 26.591 | 50.382 | 24.287 | 7.230 | 15.280 | 34.606 |\n",
      "\u001b[32m[03/02 11:22:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 6.893  | saturation | 26.309 | artifact   | 18.553 |\n",
      "| blur        | 31.236 | contrast   | 38.430 | bubbles    | 10.010 |\n",
      "| instrument  | 67.951 | blood      | 13.345 |            |        |\n",
      "\u001b[32m[03/02 11:22:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[03/02 11:22:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0332 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/02 11:22:18 d2.evaluation.evaluator]: \u001b[0mInference done 166/300. 0.0311 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/02 11:22:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.550135 (0.032373 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/02 11:22:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.030864 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/02 11:22:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/02 11:22:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[03/02 11:22:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=6.15s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.39s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.485\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.241\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.332\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.404\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.095\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.467\n",
      "\u001b[32m[03/02 11:22:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 26.016 | 48.474 | 24.089 | 3.041 | 13.285 | 33.219 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/02 11:22:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 6.177  | saturation | 23.369 | artifact   | 17.364 |\n",
      "| blur        | 34.093 | contrast   | 39.415 | bubbles    | 10.128 |\n",
      "| instrument  | 66.347 | blood      | 11.238 |            |        |\n",
      "\u001b[32m[03/02 11:22:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[03/02 11:22:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0309 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/02 11:22:36 d2.evaluation.evaluator]: \u001b[0mInference done 168/300. 0.0306 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/02 11:22:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.533062 (0.032315 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/02 11:22:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.030779 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/02 11:22:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/02 11:22:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[03/02 11:22:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=5.94s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.36s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.476\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.136\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.252\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.397\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.086\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.478\n",
      "\u001b[32m[03/02 11:22:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 25.641 | 47.562 | 23.947 | 2.636 | 13.589 | 33.120 |\n",
      "\u001b[32m[03/02 11:22:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 6.825  | saturation | 22.801 | artifact   | 15.633 |\n",
      "| blur        | 32.167 | contrast   | 39.207 | bubbles    | 9.076  |\n",
      "| instrument  | 68.577 | blood      | 10.840 |            |        |\n",
      "\u001b[32m[03/02 11:22:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[03/02 11:22:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0314 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/02 11:22:55 d2.evaluation.evaluator]: \u001b[0mInference done 167/300. 0.0307 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/02 11:22:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.478470 (0.032130 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/02 11:22:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.030630 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/02 11:22:59 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/02 11:22:59 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[03/02 11:22:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=5.69s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.34s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.257\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.487\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.234\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.028\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.136\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.254\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.277\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.470\n",
      "\u001b[32m[03/02 11:23:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 25.729 | 48.720 | 23.403 | 2.812 | 13.646 | 33.062 |\n",
      "\u001b[32m[03/02 11:23:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 6.589  | saturation | 24.814 | artifact   | 15.841 |\n",
      "| blur        | 30.497 | contrast   | 37.419 | bubbles    | 9.122  |\n",
      "| instrument  | 68.138 | blood      | 13.410 |            |        |\n",
      "\u001b[32m[03/02 11:23:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[03/02 11:23:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0317 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/02 11:23:13 d2.evaluation.evaluator]: \u001b[0mInference done 166/300. 0.0310 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/02 11:23:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.488467 (0.032164 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/02 11:23:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.030748 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/02 11:23:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/02 11:23:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[03/02 11:23:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=5.75s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.34s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.478\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.129\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.329\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.384\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.259\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.454\n",
      "\u001b[32m[03/02 11:23:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 25.554 | 47.844 | 23.349 | 2.566 | 12.866 | 32.885 |\n",
      "\u001b[32m[03/02 11:23:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 5.625  | saturation | 23.463 | artifact   | 15.645 |\n",
      "| blur        | 34.103 | contrast   | 36.825 | bubbles    | 9.182  |\n",
      "| instrument  | 68.164 | blood      | 11.422 |            |        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/02 11:23:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[03/02 11:23:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0327 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/02 11:23:31 d2.evaluation.evaluator]: \u001b[0mInference done 168/300. 0.0305 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/02 11:23:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.444027 (0.032014 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/02 11:23:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.030471 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/02 11:23:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/02 11:23:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[03/02 11:23:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.84s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.27s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.261\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.484\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.028\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.138\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.332\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.261\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.386\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.277\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.455\n",
      "\u001b[32m[03/02 11:23:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 26.146 | 48.384 | 23.664 | 2.826 | 13.789 | 33.225 |\n",
      "\u001b[32m[03/02 11:23:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 6.582  | saturation | 24.854 | artifact   | 15.352 |\n",
      "| blur        | 32.587 | contrast   | 37.652 | bubbles    | 9.567  |\n",
      "| instrument  | 70.243 | blood      | 12.333 |            |        |\n",
      "\u001b[32m[03/02 11:23:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[03/02 11:23:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0314 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/02 11:23:48 d2.evaluation.evaluator]: \u001b[0mInference done 169/300. 0.0305 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/02 11:23:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.530387 (0.032306 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/02 11:23:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.030739 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/02 11:23:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/02 11:23:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[03/02 11:23:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.76s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.26s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.259\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.480\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.027\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.332\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.261\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.384\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.283\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.454\n",
      "\u001b[32m[03/02 11:23:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 25.901 | 47.998 | 23.804 | 2.729 | 13.281 | 33.247 |\n",
      "\u001b[32m[03/02 11:23:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 6.349  | saturation | 24.422 | artifact   | 15.130 |\n",
      "| blur        | 31.846 | contrast   | 37.883 | bubbles    | 9.370  |\n",
      "| instrument  | 69.988 | blood      | 12.219 |            |        |\n",
      "\u001b[32m[03/02 11:24:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[03/02 11:24:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0311 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/02 11:24:05 d2.evaluation.evaluator]: \u001b[0mInference done 166/300. 0.0307 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/02 11:24:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.603916 (0.032556 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/02 11:24:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.030574 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/02 11:24:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/02 11:24:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[03/02 11:24:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.66s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.25s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.259\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.481\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.027\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.135\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.259\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.362\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.383\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.450\n",
      "\u001b[32m[03/02 11:24:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 25.888 | 48.076 | 23.736 | 2.745 | 13.462 | 33.069 |\n",
      "\u001b[32m[03/02 11:24:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 6.385  | saturation | 24.511 | artifact   | 14.957 |\n",
      "| blur        | 31.675 | contrast   | 37.555 | bubbles    | 9.479  |\n",
      "| instrument  | 70.065 | blood      | 12.475 |            |        |\n"
     ]
    }
   ],
   "source": [
    "for checkpoint in checkpoints:\n",
    "    print(\"-------------------------> \" + checkpoint)\n",
    "    cfg = get_cfg()\n",
    "\n",
    "    cfg.merge_from_file(\"output/config.yaml\")\n",
    "    model = build_model(cfg)\n",
    "    DetectionCheckpointer(model).load(\"output/model_\"+checkpoint+\".pth\")\n",
    "    \n",
    "    evaluator = COCOEvaluator(\"ead_validation_1\", cfg, False, output_dir=\"./output/\")\n",
    "    val_loader = build_detection_test_loader(cfg, \"ead_validation_1\")\n",
    "    a = inference_on_dataset(model, val_loader, evaluator)\n",
    "    \n",
    "    APs.append(a.get('bbox')['AP'])\n",
    "    AP50s.append(a.get('bbox')['AP50'])\n",
    "    AP75s.append(a.get('bbox')['AP75'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6c0eec2590>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAd70lEQVR4nO3deZCcd33n8fe3j7k1mtE1OkaWBL4tnyNkbGMj2YFwBbwUoWDDxkmx0abYTch6IRhqF5aqJQm7WWCrNkktsQFRGIQxUFAONhh7FGN8SrJsyyeybNm6rxlJo7m7v/vH8/R0z6WZ7plW90/+vKqe6ufWd0Y9n+fXv34Oc3dERCQ8iUoXICIipVGAi4gESgEuIhIoBbiISKAU4CIigUqdyX9swYIFvnLlypK2PXXqFI2NjbNb0CxQXcVRXcVRXcWp1rpgZrVt3br1iLsvHLfA3c/Y0NHR4aXq7OwsedtyUl3FUV3FUV3Fqda63GdWG7DFJ8hUdaGIiARKAS4iEigFuIhIoBTgIiKBUoCLiARKAS4iEigFuIhIoM7ohTwle+k+Vrz2c3hyJ9TPg4Z5o19rGipdoYjIGRdGgO+8n1Wv3Qmv3Tnx8lRdHOjzoaF14pAvfG2YB7VzIaEPICISrjAC/P3/m3+tfw/vfNul0HsM+o5N/JobP/hc9NrXBZ6deJ+WgPqJwr61YHr++ANAqubM/uwiIpMII8ABT6RhzuJomK5sFgaOx8HeBb1HJz8AHN8DB56J1hnun3yfNU1xoEfhf15/Hby1EdrXgNnMf1ARkWmaVoCb2WvASSADDLv7GjObB/wQWAm8BnzU3bvKU2aJErlWdmtx2w32TtLK7xozfZTFBx6BO+6FRRfDVbfAZR+NWusiImVWTAt8vbsfKZi+DXjA3f/OzG6Lpz83q9VVSk1DNMxtn3LVR379C65vOQjbNsJ9n4P7vwgXfzAK85XvUKtcRMpmJl0oHwLWxeMbgc2cLQFehEyqAdb8aTTsfwa2fReeuQue/RHMeytc9cdwxb+FpkWVLlVEzjLm03gqvZm9CnQBDvw/d/+mmXW7e0u83ICu3PSYbTcAGwDa2to6Nm3aVFKhPT09NDU1lbRtOU1UVyIzwMLDv2XJ/vtpOf48WUtydP5a9i95N8fmXQ6WrEhd1UB1FUd1Fada64KZ1bZ+/fqt7r5m3IKJ7jE7dgCWxa+LgKeBG4DuMet0TbWfN+X9wA+95H7fF9y/usr9S83uX7vEvfPv3Lv3VLauClFdxVFdxanWutwreD9wd98bvx4CfgqsBQ6a2RKA+PVQSYeWs93C8+H3vwK3vgAf+TbMfyts/hv4xmq48w/hhXsgM1TpKkUkQFMGuJk1mtmc3DjwbmAH8HPglni1W4CflavIs0KqFlZ/GP74Z/Dpp+Edt0Z95j/8I/j6JfDrL8OxXZWuUkQCMp0vMduAn0bd3KSA77v7fWb2JHCXmX0S2A18tHxlnmVaV8JN/w3WfR5+96voDJbffgMe/hqsuiE6g+WiP4hCX0RkElMGuLvvAi6fYP5R4KZyFPWmkUzBhe+LhhP74Kk74anvwo8/GV0sdPnHo7NYFl1Y6UpFpArpZiDVonkpvPOz8JdPwyd+ErXEn/gm/OPVcMe7o3AfPFXpKkWkigRzKf2bRiIB594UDT2H4ekfRF0sP/sU3HcbXPqRqItl6RWVrlREKkwBXs2aFsJ1fwnX/gXsfiQK8u3fhy3fgiWXR0F+6R9CXXOlKxWRClCAh8AMVl4XDe/9KjzzoyjM/+VW+NV/hUs+HPWVL1+rS/eLkRmGA0/D7kc57+WHoe5FWLw6uq+N7mcjAVCAh6a+Fa7eAGv/DPZtg60bYcePYfv3YOFFUZBf/rFKV1mdhvpgzxZ4/dHoE82eJ2GwB4C2ZB3cd29+3eZl0HYJtK3Ov84/N/riWaRK6N0YKjNY1hENv/8V2PGTqFX+y8/Dr7/EJa1XQXIbLL4MFl8Kc9oqXfGZ19cNbzwOu38Lux+FfU9BdgiwqJV9+cdhxTVwzrU8vPVF1q25CA7uiO4nfyB+feVByA5H+0vWRmcEFYZ622ponF/RH1PevBTgZ4PaOdBxSzQc2AHbvkvTMz+FB76cX6epLQrykeEymPcWSJT/vixnzIn98PojUVi//mgUwDgk0rD0SrjmU3DOtXDO1eNvMWwv5e83f+7v5ecPD8KRl+Ngj0N9569he8HToZoWR4G+eHU+3OefF+7DP7IZ6DkYndp6fE/0emJvNBzfCyf2cX3PIdjSGj/0pGBoXDD5PF3XMOsU4Gebxavhff+Txxvex7qrr4hC58Cz0bD/Gdi1Od+iTDfEwRMH+uLLYNFFYTxj1D26cnX3I/kuka5Xo2XpRlj+tuhCqRXXRp9SSv2ZUjXR73Tx6tHzew7nA/3gc9H4Y/8EmcFoeSINCy+MW+qX5H/Plb4rZTYDPYfGBHJu2BdNn9wPnhm9Xao+OtV17jJYdT37jvaxfFFzdG/8U0ei30Hv0ejBKUxyg7yapukFfW6oa9FjD6egAD+b1bdE9yRf+Y78vOEBOPxSPtQPPAvP/jg6swWiR83NP298a71pYWV+hpxsJgqJ3Y9ErezXH4taiRBd9LTiWnjbv4+6RBZfBsl0eetpWghN6+Gt6/PzMkNwdGc+0A/sgFcfgmcK7sDZuHB090vbJbDwgtlpnY4N53Et6H1ROOcO4DmpuqjPPw5nmpdG07l5zcuiTywFX5C/snkzy9etG19DZhj6u6NQ7z0aD0fyT8PKze85BIdeiMaHeif+eSwR/d9OJ+xz8wq5Rz9rbsgMRb+jwnnZTNStNmq6cJvhMeuXsk20vMEvndn/7wQU4G82qVpYclk05LhD9+vRI+Vyof7G47Dj7vw6c5aMD/XWVeVrIQ0PwN5t+S6RNx6HgRPRsrnLYdU7R/qvWXB+dbTUkunoE8yii6Lz9XN6j+VDPddqf/L2/KP7EqnoZxhprcfhXvj4wGwGTh0e02IubEFPEc7NS6MD+TTCeWa/g1QUpGPD9HQGe8eEffS0q9EHgaNRV1ZufJJn3d5gafiNRb+HyZ6He6Yk0tH/bSIFiSS15y+d9X9CAS7RH2/rimi46A/y83uP5btg9sfhvvOB/Mfrmqa4a+CyfLAvugjS9cXXMHAy/sIx7g7ZuxUyA9GyBRdENwJbcR2ccw20LJ/5z3wmNcyLWrarrs/Py2bg6Cuju2Fefyx6EEhO/TyuSs2Dpwbh5L7iwrl5afREqdkM53LJPQFruv+v2WzUyu89VtC6jwJ/z8vPcs6KFaOCMz8+2ZCMDr7T3qZg+ch2Y7cZ/91S1+bNs/t7QwEup9MwL7qkf9UN+XlD/XD4xdFdME9vgif/OVpuyag1Oba1PvZMjZ7DBV84PhLtx7PR9ksuj06TPOeaaDgbz/JIJKNbDS88Pzo45fR1w6HnR1rsw7u2w/IL49byUmhuDyucyyGRiN6bDfOAc0ct2pXZzDkTde2cpRTgUpx0XXQZf+Gl/NksdL82OtR3/xaevSu/TvMyWHwpF5wYhGc/A0d/F81P1UH72+D6z0RdIu1robY6n6hyRtS3RP35K64F4JnNm1n3JgokKY4CXGYukYhOSZz3Frj4Q/n5p47CwWdHnQUzv3sfrHw7XPmJKKSWXBHu6XYiFaYAl/JpnA9vWRcNsUfUohSZNVXw1b2IiJRCAS4iEigFuIhIoBTgIiKBUoCLiARKAS4iEigFuIhIoBTgIiKBUoCLiARKAS4iEigFuIhIoBTgIiKBUoCLiARKAS4iEigFuIhIoKYd4GaWNLOnzOyeePo7ZvaqmW2Phyum2oeIiMyeYh7o8GngBaC5YN5n3f3uSdYXEZEymlYL3MzagfcDt5e3HBERmS5z96lXMrsb+FtgDvAZd/+AmX0HuAYYAB4AbnP3gQm23QBsAGhra+vYtGlTSYX29PTQ1FR9D7tVXcVRXcVRXcWp1rpgZrWtX79+q7uvGbfA3U87AB8A/jEeXwfcE48vAQyoBTYCX5xqXx0dHV6qzs7OkrctJ9VVHNVVHNVVnGqty31mtQFbfIJMnU4XynXAB83sNWATcKOZfc/d98f7HgC+Dawt6dAiIiIlmTLA3f3z7t7u7iuBjwEPuvsnzGwJgJkZcDOwo6yViojIKMWchTLWnWa2kKgbZTvw57NTkoiITEdRAe7um4HN8fiNZahHRESmSVdiiogESgEuIhIoBbiISKAU4CIigVKAi4gESgEuIhIoBbiISKAU4CIigVKAi4gESgEuIhIoBbiISKAU4CIigVKAi4gESgEuIhIoBbiISKAU4CIigVKAi4gESgEuIhIoBbiISKAU4CIigVKAi4gESgEuIhIoBbiISKAU4CIigVKAi4gESgEuIhIoBbiISKAU4CIigVKAi4gESgEuIhKoaQe4mSXN7CkzuyeeXmVmj5vZTjP7oZnVlK9MEREZq5gW+KeBFwqmvwp83d3PBbqAT85mYSIicnrTCnAzawfeD9weTxtwI3B3vMpG4OZyFCgiIhObbgv8G8BfA9l4ej7Q7e7D8fQeYNks1yYiIqdh7n76Fcw+ALzP3T9lZuuAzwB/AjwWd59gZsuBe9199QTbbwA2ALS1tXVs2rSppEJ7enpoamoqadtyUl3FUV3FUV3Fqda6YGa1rV+/fqu7rxm3wN1POwB/S9TCfg04APQCdwJHgFS8zjXAL6faV0dHh5eqs7Oz5G3LSXUVR3UVR3UVp1rrcp9ZbcAWnyBTp+xCcffPu3u7u68EPgY86O5/BHQCH4lXuwX4WUmHFhERKclMzgP/HHCrme0k6hO/Y3ZKEhGR6UgVs7K7bwY2x+O7gLWzX5KIiEyHrsQUEQmUAlxEJFAKcBGRQCnARUQCpQAXEQmUAlxEJFAKcBGRQCnARUQCpQAXEQmUAlxEJFAKcBGRQCnARUQCpQAXEQmUAlxEJFAKcBGRQCnARUQCpQAXEQmUAlxEJFAKcBGRQCnARUQCpQAXEQmUAlxEJFAKcBGRQCnARUQCpQAXEQmUAlxEJFAKcBGRQCnARUQCpQAXEQmUAlxEJFAKcBGRQE0Z4GZWZ2ZPmNnTZvacmX05nv8dM3vVzLbHwxXlL1dERHJS01hnALjR3XvMLA08bGb3xss+6+53l688ERGZzJQB7u4O9MST6XjwchYlIiJTsyifp1jJLAlsBc4F/sHdP2dm3wGuIWqhPwDc5u4DE2y7AdgA0NbW1rFp06aSCu3p6aGpqamkbctJdRVHdRVHdRWnWuuCmdW2fv36re6+ZtwCd5/2ALQAncBqYAlgQC2wEfjiVNt3dHR4qTo7O0vetpxUV3FUV3FUV3GqtS73mdUGbPEJMrWos1DcvTsO8Pe4+/543wPAt4G1JR1aRESkJNM5C2WhmbXE4/XAu4AXzWxJPM+Am4Ed5SxURERGm85ZKEuAjXE/eAK4y93vMbMHzWwhUTfKduDPy1iniIiMMZ2zUJ4Brpxg/o1lqUhERKZFV2KKiARKAS4iEigFuIhIoBTgIiKBUoCLiARKAS4iEigFuIhIoBTgIiKBUoCLiARKAS4iEigFuIhIoBTgIiKBUoCLiARKAS4iEigFuIhIoBTgIiKBUoCLiARKAS4iEigFuIhIoBTgIiKBUoCLiARKAS4iEigFuIhIoBTgIiKBUoCLiARKAS4iEigFuIhIoBTgIiKBUoCLiARKAS4iEqgpA9zM6szsCTN72syeM7Mvx/NXmdnjZrbTzH5oZjXlL1dERHKm0wIfAG5098uBK4D3mNnbga8CX3f3c4Eu4JPlK1NERMaaMsA90hNPpuPBgRuBu+P5G4Gby1KhiIhMyNx96pXMksBW4FzgH4D/BTwWt74xs+XAve6+eoJtNwAbANra2jo2bdpUUqE9PT00NTWVtG05qa7iqK7iqK7iVGtdMLPa1q9fv9Xd14xb4O7THoAWoBN4B7CzYP5yYMdU23d0dHipOjs7S962nFRXcVRXcVRXcaq1LveZ1QZs8QkytaizUNy9Ow7wa4AWM0vFi9qBvSUdWkREpCTTOQtloZm1xOP1wLuAF4iC/CPxarcAPytXkSIiMl5q6lVYAmyM+8ETwF3ufo+ZPQ9sMrP/ATwF3FHGOkVEZIwpA9zdnwGunGD+LmBtOYoSEZGp6UpMEZFAKcBFRAKlABcRCZQCXEQkUApwEZFAKcBFRAKlABcRCZQCXEQkUApwEZFAKcBFRAKlABcRCZQCXEQkUApwEZFAKcBFRAKlABcRCVQQAX745ADdA1my2akfwCwi8mYxnSfyVNz/ffB3bHy0j88+dC+L5tSxZG4di+fmXutHTS9sqiWVDOK4JCIyI0EE+M1XLiPTvZ85bcs5cLyf/cf72LH3OPc/f5CB4eyodRMGC+fURsHeXBj0dSyJw35Rcy21qWSFfhoRkdkRRIBfeU4rx1ekWbfuwlHz3Z3u3iEOnOiPg72fA8f7otcT/ew83MNvfneYU4OZcftc0FTD4rl1LG6uZ/HcWpbMrWdxcz7sF8+to6EmiF+PiLxJBZ1QZkZrYw2tjTVctKR50vVO9g8VBHwU7rmw39PVy5bdx+juHRq33dz69OjumuaoBd9W0Kp3V7+8iFRG0AE+XXPq0sypS3Ne25xJ1+kbzMTB3jcq7Pcf7+fgiX527D3BkZ6BcdvVJeGc7f/K0pZ6lrXUj7wua43G2+aoT15EyuNNEeDTUV+TZNWCRlYtaJx0nYHhDIdODIxqwT+xYyeJpkb2dvfx9BvddI1pyScTxuLmOpa21E0a8k21+m8QkeIpOYpQm0qyfF4Dy+c1jMw7P/sG69atGZnuHRxmX3cfe7v7o9euvni6j22vd/Evz+xneMzpkM11KZa1NrBsTMgvbamnvbWehU21JBJ2xn5OEQmDAnyWNdSkOHfRHM5dNHF3TSbrHD45wN441PfFw96uPvZ09fHEq8c40T88apt00lg8t250670g5Je11FNfo7NqpHyGMln2d/ezp7uXvV19PL5rkFdSr9JUm6SxNkVjbYqm2hSNNfFrPL82lcBMjY9yUYCfYcmEjZzl0rGidcJ1TvYPsS9uwe8ZE/KPvXKUAyf6GXtN07zGGpa25EO+98gQR+bsobUhTWtjDfMaoi97m+tS+oOScfqHMuzpihoVe7v62NvdG03H8w5O8J7j5een3G8qYflwj0M9F/TR+JgDQG2Kxpqx85Ijy9L6PmkUBXgVmlOX5oLFaS5YPHErfjiT5cCJ/pGQL2zN7zp8it/87gi9gxl++NLT47ZNJYyWhjStcaDngn1eYzyvoYZ5jfllLY1p5tQq9EN3sn+Ivd197DmWf79En/p62dvdx5GewVHrp+KGRntrPde+dQHLWutpj7v0lrXW8+L2J7j6muvoGRjm1EAmfo2GkfHB/Pz88gwn+4c5cLx/ZJ1TA8PjuhUnU5NK5A8GNfnQz83rOjzAQyefJ/d2NciPmzHyLjYwbOL1xszPTeTWye0lGic/XvA3MtF683pHX7MyGxTgAUolE7S3NtDe2jDhcnfnvgc2c8mVV9PVO8ix3kG6Tg1y7NRgNH1qiK54fNeRHo7tHqKrd5DMJH9EqYQVhH2aeY01tDScPvwba5IVDX13J5N1huMhk3GGslmGM85w4WvWGc44rx7PsPTgSepSSerSCWrTSerTSdJJq/qDl7vT1Ts0quWca01Hrejecd1yNakE7fEX6RcvbR75Un1ZSwPtrfW0NdeRPM33Lq8mjZaG6H0wG/UPDGdHAr5nYJhTg8NjDgqZcQeI3Lyu3kHe6OqldyDD8d5hkgfeGNmvj/wbkJuKxiG30HF8ZJyRU4M9Xne23NpRO3s7iynAz0JmRn3KOGd+A+fMnzjkx3J3TvQPjwR7YdDnDgBdvYN0nRri5YM9I9OTNZxqkglaxwV7mmMHB3mk9wWGMlkyWWco4wznxrPR+PCo19FBm9tuOOuj9pGJQ3kom59XtEcfGjcrYVCXTlIXB3ptOjES8vU1yXg8nh+vUzeyTpK6miR1qcSofdSlc9P5+XXpaL2JTjnNZp3DPQMFodw70rWRe+0dc7FaY02S9tYGlrXWs2ZF60jLORfUCxqr54txMxv5Hcxvmtm+Nm/ezLp162alrrHcpw76woMBjD5wPPrwb2a9JgW4ANEf0dz6NHPr06xk8lMpC2Wzzon+Ibp6h6LWfUHYH+sdpPvU0Mj0CwdO0HVqkBN9Q9Ts2U0qYaSSRiqZyI8ncuP5eelEglQiQV3aRpalk0YykSAdr5NM5OYZ6dy2uf0k4/FEfruRecloH8mE8dxzOzjvwovpH8rSP5ShfyjDwHCWvsFovH84Q/9Qlr6hDANDmZH1unuH4vWzDAxnovWHs5N+mplKKmHxgSIK+IH+fo7ffx+DmdEfv1sa0ixrqectCxu5/ryFURdHHNDtrfXMrU9X/SeH0Jjlu1biOUVtf7pPNKVSgEvJEon8x+jTnT9fqJwtpJmoOfwi6y5bOmv7G8pkR4I9d0DoH8rSnwv5oSjo88sK180fKPYdOMDl568Y6e5ob23QtQMyYsp3gZktB74LtBF9Wvimu/8fM/vvwJ8Bh+NVv+DuvyhXoSIhSScTpJMJ5tTNbD/RAe+i2SlKzjrTOYwPA//F3beZ2Rxgq5ndHy/7urv/ffnKExGRyUwZ4O6+H9gfj580sxeAZeUuTERETs+KuZuema0EHgJWA7cCfwKcALYQtdK7JthmA7ABoK2trWPTpk0lFdrT00NT0wy/oi4D1VUc1VUc1VWcaq0LZlbb+vXrt7r7mnELolNjph6AJmAr8OF4ug1IEj2W7SvAt6baR0dHh5eqs7Oz5G3LSXUVR3UVR3UVp1rrcp9ZbcAWnyBTp3VdqpmlgR8Dd7r7T+LgP+juGXfPAv8MrC3p0CIiIiWZMsAtOpn0DuAFd/9awfwlBav9G2DH7JcnIiKTmc5ZKNcB/w541sy2x/O+AHzczK4gOrXwNeA/lKVCERGZ0HTOQnmYiS850jnfIiIVVNRZKDP+x8wOA7tL3HwBcGQWy5ktqqs4qqs4qqs41VoXzKy2Fe6+cOzMMxrgM2FmW3yi02gqTHUVR3UVR3UVp1rrgvLUpruji4gESgEuIhKokAL8m5UuYBKqqziqqziqqzjVWheUobZg+sBFRGS0kFrgIiJSQAEuIhKoIALczN5jZi+Z2U4zu63S9QCY2bfM7JCZVdUtBMxsuZl1mtnzZvacmX260jUBmFmdmT1hZk/HdX250jUVMrOkmT1lZvdUupYcM3vNzJ41s+1mtqXS9eSYWYuZ3W1mL5rZC2Z2TRXUdEH8e8oNJ8zsrypdF4CZ/ef4Pb/DzH5gZjN8zEfBvqu9D9zMksDLwLuAPcCTwMfd/fkK13UD0AN8191XV7KWQvE9apZ4wQM4gJur4PdlQKO798Q3R3sY+LS7P1bJunLM7FZgDdDs7h+odD0QBTiwxt2r6sIUM9sI/MbdbzezGqDB3bsrXVdOnBl7gavdvdQLB2erlmVE7/WL3b3PzO4CfuHu35mN/YfQAl8L7HT3Xe4+CGwCPlThmnD3h4Bjla5jLHff7+7b4vGTQFU8gCO+K2ZPPJmOh6poPZhZO/B+4PZK11LtzGwucAPRDe5w98FqCu/YTcArlQ7vAimg3sxSQAOwb7Z2HEKALwPeKJjeQxUEUgjiB3BcCTxe2UoicTfFduAQcL+7V0VdwDeAvwayU614hjnwKzPbGj8YpRqsInoO7rfjLqfbzWx6T7Q+cz4G/KDSRQC4+17g74HXiZ5sdtzdfzVb+w8hwKUEZtZEdA/3v3L3E5WuByC+f/wVQDuw1swq3vVkZh8ADrn71krXMoF3uPtVwHuB/xh321VaCrgK+Cd3vxI4BVTF91IAcZfOB4EfVboWADNrJeoxWAUsBRrN7BOztf8QAnwvsLxguj2eJ5OY6AEc1ST+yN0JvKfStRDdLvmDcX/zJuBGM/teZUuKxK033P0Q8FOq46Epe4A9BZ+e7iYK9GrxXmCbux+sdCGx3wNedffD7j4E/AS4drZ2HkKAPwmcZ2ar4qPrx4CfV7imqjXZAzgqzcwWmllLPF5P9KX0i5WtCtz98+7e7u4rid5bD7r7rLWQSmVmjfGX0MRdFO+mCh6a4u4HgDfM7IJ41k1ARb8gH+PjVEn3Sex14O1m1hD/bd5E9L3UrJjOAx0qyt2Hzew/Ab8kegbnt9z9uQqXhZn9AFgHLDCzPcCX3P2OylYFTPIADnev9P3blwAb4zMEEsBd7l41p+xVoTbgp9HfPCng++5+X2VLGvEXwJ1xg2oX8KcVrgcYOdC9iyp6uIy7P25mdwPbgGHgKWbxkvqqP41QREQmFkIXioiITEABLiISKAW4iEigFOAiIoFSgIuIBEoBLiISKAW4iEig/j8cWJwJKrRkZgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.grid(True)\n",
    "plt.plot(APs)\n",
    "plt.plot(AP50s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27.11970322623286,\n",
       " 26.59079723014172,\n",
       " 26.01635025895878,\n",
       " 25.640825753182302,\n",
       " 25.72877803741555,\n",
       " 25.55363437130969,\n",
       " 26.146248195991777,\n",
       " 25.9008371934243,\n",
       " 25.88763804388933]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50.744396266427984,\n",
       " 50.38235630204665,\n",
       " 48.473573976603774,\n",
       " 47.562074755695356,\n",
       " 48.72002845766375,\n",
       " 47.84418549242015,\n",
       " 48.383675813494406,\n",
       " 47.99780556971995,\n",
       " 48.076151015158466]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP50s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24.39066571521305,\n",
       " 24.28661023875462,\n",
       " 24.089207900779837,\n",
       " 23.947010399791267,\n",
       " 23.402557063036973,\n",
       " 23.34886824583941,\n",
       " 23.66353294782925,\n",
       " 23.804181357168495,\n",
       " 23.736164253915067]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP75s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
