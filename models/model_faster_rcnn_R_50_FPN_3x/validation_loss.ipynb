{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n"
     ]
    }
   ],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from google.colab.patches import cv2_imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metadata(name='ead_validation_1', thing_classes=['specularity', 'saturation', 'artifact', 'blur', 'contrast', 'bubbles', 'instrument', 'blood'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ead_dicts(img_dir):    \n",
    "    images_path = os.path.join(img_dir, '*.jpg')\n",
    "    images = glob.glob(images_path)\n",
    "    \n",
    "    dataset_dicts = []\n",
    "    \n",
    "    for idx, image_path in enumerate(images):\n",
    "        text_path= image_path.replace(\".jpg\", \".txt\")\n",
    "        \n",
    "        record = {}\n",
    "\n",
    "        height, width = cv2.imread(image_path).shape[:2]\n",
    "        \n",
    "        record[\"file_name\"] = image_path\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width        \n",
    "        \n",
    "        with open(text_path) as f:\n",
    "            contents = f.readlines()\n",
    "        \n",
    "        objs = []\n",
    "        for content in contents:\n",
    "            information = content.split(' ')\n",
    "            \n",
    "            obj = {\n",
    "                \"bbox\": [(float(information[1]) - float(information[3]) / 2)*width, \n",
    "                         (float(information[2]) - float(information[4]) / 2)*height, \n",
    "                         (float(information[1]) + float(information[3]) / 2)*width, \n",
    "                         (float(information[2]) + float(information[4]) / 2)*height],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                \"category_id\": int(information[0])\n",
    "            }\n",
    "            objs.append(obj)\n",
    "                        \n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)                        \n",
    "    return dataset_dicts\n",
    "\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "data_path = r'/home/ws2080/Desktop/codes/models/research/ead/data/'\n",
    "train_path = r'/home/ws2080/Desktop/data/training/train/'\n",
    "validation_path = r'/home/ws2080/Desktop/data/training/validation/'\n",
    "\n",
    "'''\n",
    "d= 'train'\n",
    "DatasetCatalog.register(\"ead_train_1\", lambda d=d: get_ead_dicts(train_path))\n",
    "MetadataCatalog.get(\"ead_train_1\").set(thing_classes=[\"specularity\", \"saturation\", \"artifact\", \"blur\", \"contrast\", \"bubbles\", \"instrument\", \"blood\"])\n",
    "\n",
    "'''\n",
    "\n",
    "d= 'validation'\n",
    "DatasetCatalog.register(\"ead_validation_1\", lambda d=d: get_ead_dicts(validation_path))\n",
    "MetadataCatalog.get(\"ead_validation_1\").set(thing_classes=[\"specularity\", \"saturation\", \"artifact\", \"blur\", \"contrast\", \"bubbles\", \"instrument\", \"blood\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'output_9'\n",
    "checkpoints = ['0009999',\n",
    "               '0019999',\n",
    "               '0029999',\n",
    "               '0039999',\n",
    "               '0049999',\n",
    "               '0059999',\n",
    "               '0069999',    \n",
    "               '0079999',\n",
    "               '0089999',    \n",
    "               '0099999', \n",
    "               '0109999', \n",
    "               '0119999', \n",
    "               '0129999',\n",
    "               '0139999',\n",
    "               '0149999',\n",
    "               '0159999',\n",
    "               '0169999',\n",
    "               '0179999',\n",
    "               '0189999',\n",
    "               '0199999']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "APs =[]\n",
    "AP50s = []\n",
    "AP75s = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/23 21:58:30 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'ead_validation_1'\n",
      "\u001b[32m[02/23 21:58:30 d2.data.datasets.coco]: \u001b[0mConverting dataset annotations in 'ead_validation_1' to COCO format ...)\n",
      "\u001b[32m[02/23 21:58:31 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
      "\u001b[32m[02/23 21:58:32 d2.data.datasets.coco]: \u001b[0mConversion finished, num images: 300, num annotations: 3598\n",
      "\u001b[32m[02/23 21:58:32 d2.data.datasets.coco]: \u001b[0mCaching annotations in COCO format: ./output/ead_validation_1_coco_format.json\n",
      "\u001b[32m[02/23 21:58:33 d2.data.build]: \u001b[0mDistribution of instances among all 8 categories:\n",
      "\u001b[36m|  category   | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:-----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| specularity | 1399         | saturation | 173          |  artifact  | 969          |\n",
      "|    blur     | 96           |  contrast  | 224          |  bubbles   | 622          |\n",
      "| instrument  | 62           |   blood    | 53           |            |              |\n",
      "|    total    | 3598         |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/23 21:58:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 21:58:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0290 s / img. ETA=0:00:08\n",
      "\u001b[32m[02/23 21:58:39 d2.evaluation.evaluator]: \u001b[0mInference done 185/300. 0.0270 s / img. ETA=0:00:03\n",
      "\u001b[32m[02/23 21:58:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.478566 (0.028741 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 21:58:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.026893 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 21:58:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 21:58:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 21:58:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=6.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.36s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.485\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.117\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.137\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.361\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.403\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.476\n",
      "\u001b[32m[02/23 21:58:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.541 | 48.488 | 18.977 | 11.732 | 13.739 | 28.457 |\n",
      "\u001b[32m[02/23 21:58:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 8.893  | saturation | 24.610 | artifact   | 16.761 |\n",
      "| blur        | 26.182 | contrast   | 35.227 | bubbles    | 7.450  |\n",
      "| instrument  | 59.105 | blood      | 10.104 |            |        |\n",
      "\u001b[32m[02/23 21:58:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 21:58:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0284 s / img. ETA=0:00:08\n",
      "\u001b[32m[02/23 21:58:58 d2.evaluation.evaluator]: \u001b[0mInference done 185/300. 0.0273 s / img. ETA=0:00:03\n",
      "\u001b[32m[02/23 21:59:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.584147 (0.029099 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 21:59:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.027416 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 21:59:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 21:59:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 21:59:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=5.10s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.31s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.499\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.154\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.405\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.261\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.485\n",
      "\u001b[32m[02/23 21:59:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 25.649 | 49.922 | 23.041 | 8.420 | 15.386 | 31.584 |\n",
      "\u001b[32m[02/23 21:59:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.630  | saturation | 25.376 | artifact   | 19.730 |\n",
      "| blur        | 27.694 | contrast   | 37.620 | bubbles    | 9.353  |\n",
      "| instrument  | 61.713 | blood      | 14.076 |            |        |\n",
      "\u001b[32m[02/23 21:59:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 21:59:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0279 s / img. ETA=0:00:08\n",
      "\u001b[32m[02/23 21:59:16 d2.evaluation.evaluator]: \u001b[0mInference done 185/300. 0.0273 s / img. ETA=0:00:03\n",
      "\u001b[32m[02/23 21:59:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.509878 (0.028847 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 21:59:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.027081 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 21:59:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 21:59:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 21:59:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=5.25s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.33s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.499\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.052\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.145\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.368\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.401\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.464\n",
      "\u001b[32m[02/23 21:59:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 25.237 | 49.909 | 22.201 | 5.189 | 14.549 | 30.499 |\n",
      "\u001b[32m[02/23 21:59:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.267  | saturation | 26.494 | artifact   | 19.099 |\n",
      "| blur        | 24.427 | contrast   | 37.642 | bubbles    | 9.628  |\n",
      "| instrument  | 63.668 | blood      | 11.673 |            |        |\n",
      "\u001b[32m[02/23 21:59:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 21:59:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0295 s / img. ETA=0:00:08\n",
      "\u001b[32m[02/23 21:59:34 d2.evaluation.evaluator]: \u001b[0mInference done 186/300. 0.0272 s / img. ETA=0:00:03\n",
      "\u001b[32m[02/23 21:59:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.535081 (0.028932 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 21:59:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.027064 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 21:59:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 21:59:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 21:59:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=5.51s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.32s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.241\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.490\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.212\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.132\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.238\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.360\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.099\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.472\n",
      "\u001b[32m[02/23 21:59:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 24.108 | 49.030 | 21.180 | 4.033 | 13.209 | 30.538 |\n",
      "\u001b[32m[02/23 21:59:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.444  | saturation | 23.153 | artifact   | 17.479 |\n",
      "| blur        | 26.806 | contrast   | 35.992 | bubbles    | 10.771 |\n",
      "| instrument  | 59.744 | blood      | 9.475  |            |        |\n",
      "\u001b[32m[02/23 21:59:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 21:59:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0300 s / img. ETA=0:00:08\n",
      "\u001b[32m[02/23 21:59:53 d2.evaluation.evaluator]: \u001b[0mInference done 186/300. 0.0271 s / img. ETA=0:00:03\n",
      "\u001b[32m[02/23 21:59:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.546947 (0.028973 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 21:59:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.026963 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 21:59:57 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 21:59:57 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 21:59:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=5.16s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.30s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.254\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.514\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.092\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.146\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.308\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.271\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.462\n",
      "\u001b[32m[02/23 22:00:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 25.385 | 51.352 | 22.213 | 9.232 | 14.647 | 30.750 |\n",
      "\u001b[32m[02/23 22:00:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 10.043 | saturation | 25.312 | artifact   | 17.811 |\n",
      "| blur        | 29.120 | contrast   | 36.294 | bubbles    | 9.571  |\n",
      "| instrument  | 59.691 | blood      | 15.240 |            |        |\n",
      "\u001b[32m[02/23 22:00:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 22:00:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0301 s / img. ETA=0:00:08\n",
      "\u001b[32m[02/23 22:00:11 d2.evaluation.evaluator]: \u001b[0mInference done 183/300. 0.0276 s / img. ETA=0:00:03\n",
      "\u001b[32m[02/23 22:00:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.571909 (0.029057 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:00:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.027327 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:00:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 22:00:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 22:00:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.72s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.28s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.512\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.148\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.320\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.361\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.104\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.263\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.470\n",
      "\u001b[32m[02/23 22:00:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 26.169 | 51.153 | 22.501 | 3.987 | 14.800 | 32.019 |\n",
      "\u001b[32m[02/23 22:00:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 10.841 | saturation | 24.452 | artifact   | 16.543 |\n",
      "| blur        | 32.618 | contrast   | 36.367 | bubbles    | 10.004 |\n",
      "| instrument  | 64.153 | blood      | 14.371 |            |        |\n",
      "\u001b[32m[02/23 22:00:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 22:00:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0285 s / img. ETA=0:00:08\n",
      "\u001b[32m[02/23 22:00:29 d2.evaluation.evaluator]: \u001b[0mInference done 186/300. 0.0271 s / img. ETA=0:00:03\n",
      "\u001b[32m[02/23 22:00:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.463818 (0.028691 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:00:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.027045 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:00:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 22:00:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 22:00:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.47s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.27s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.259\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.507\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.141\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.385\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.453\n",
      "\u001b[32m[02/23 22:00:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.856 | 50.718 | 23.065 | 10.645 | 14.087 | 31.273 |\n",
      "\u001b[32m[02/23 22:00:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 8.998  | saturation | 25.725 | artifact   | 18.734 |\n",
      "| blur        | 31.999 | contrast   | 35.815 | bubbles    | 9.895  |\n",
      "| instrument  | 62.731 | blood      | 12.948 |            |        |\n",
      "\u001b[32m[02/23 22:00:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 22:00:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0292 s / img. ETA=0:00:08\n",
      "\u001b[32m[02/23 22:00:47 d2.evaluation.evaluator]: \u001b[0mInference done 185/300. 0.0272 s / img. ETA=0:00:03\n",
      "\u001b[32m[02/23 22:00:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.508321 (0.028842 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:00:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.027103 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:00:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 22:00:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 22:00:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.31s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.27s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.255\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.507\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.228\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.081\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.144\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.320\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.388\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.257\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.458\n",
      "\u001b[32m[02/23 22:00:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 25.548 | 50.697 | 22.845 | 8.062 | 14.434 | 31.997 |\n",
      "\u001b[32m[02/23 22:00:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 10.293 | saturation | 24.917 | artifact   | 17.826 |\n",
      "| blur        | 31.053 | contrast   | 40.390 | bubbles    | 9.150  |\n",
      "| instrument  | 60.806 | blood      | 9.947  |            |        |\n",
      "\u001b[32m[02/23 22:00:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 22:00:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0287 s / img. ETA=0:00:08\n",
      "\u001b[32m[02/23 22:01:04 d2.evaluation.evaluator]: \u001b[0mInference done 184/300. 0.0272 s / img. ETA=0:00:03\n",
      "\u001b[32m[02/23 22:01:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.623182 (0.029231 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:01:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.027165 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:01:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 22:01:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 22:01:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.50s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.27s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.250\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.489\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.046\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.145\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.110\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.247\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.450\n",
      "\u001b[32m[02/23 22:01:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 24.953 | 48.903 | 21.985 | 4.594 | 14.475 | 30.674 |\n",
      "\u001b[32m[02/23 22:01:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.947  | saturation | 22.545 | artifact   | 16.832 |\n",
      "| blur        | 31.133 | contrast   | 36.535 | bubbles    | 9.225  |\n",
      "| instrument  | 60.552 | blood      | 12.855 |            |        |\n",
      "\u001b[32m[02/23 22:01:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 22:01:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0283 s / img. ETA=0:00:08\n",
      "\u001b[32m[02/23 22:01:22 d2.evaluation.evaluator]: \u001b[0mInference done 186/300. 0.0270 s / img. ETA=0:00:03\n",
      "\u001b[32m[02/23 22:01:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.541496 (0.028954 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:01:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.026989 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:01:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 22:01:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 22:01:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.84s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.29s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.471\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.052\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.134\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.295\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.237\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.388\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.112\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.252\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.449\n",
      "\u001b[32m[02/23 22:01:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 24.037 | 47.124 | 21.882 | 5.206 | 13.405 | 29.546 |\n",
      "\u001b[32m[02/23 22:01:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 8.634  | saturation | 21.967 | artifact   | 16.833 |\n",
      "| blur        | 29.924 | contrast   | 35.735 | bubbles    | 8.631  |\n",
      "| instrument  | 62.743 | blood      | 7.830  |            |        |\n",
      "\u001b[32m[02/23 22:01:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 22:01:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0294 s / img. ETA=0:00:08\n",
      "\u001b[32m[02/23 22:01:40 d2.evaluation.evaluator]: \u001b[0mInference done 182/300. 0.0276 s / img. ETA=0:00:03\n",
      "\u001b[32m[02/23 22:01:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.594529 (0.029134 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:01:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.027365 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:01:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 22:01:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 22:01:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.17s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.25s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.234\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.462\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.129\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.295\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.115\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.241\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
      "\u001b[32m[02/23 22:01:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 23.385 | 46.227 | 20.735 | 5.737 | 12.864 | 29.507 |\n",
      "\u001b[32m[02/23 22:01:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 11.413 | saturation | 20.078 | artifact   | 15.861 |\n",
      "| blur        | 22.922 | contrast   | 35.317 | bubbles    | 10.070 |\n",
      "| instrument  | 60.866 | blood      | 10.556 |            |        |\n",
      "\u001b[32m[02/23 22:01:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 22:01:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0284 s / img. ETA=0:00:08\n",
      "\u001b[32m[02/23 22:01:57 d2.evaluation.evaluator]: \u001b[0mInference done 185/300. 0.0272 s / img. ETA=0:00:03\n",
      "\u001b[32m[02/23 22:02:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.526350 (0.028903 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:02:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.027199 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:02:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 22:02:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 22:02:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.20s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.26s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.495\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.130\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.385\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.238\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.452\n",
      "\u001b[32m[02/23 22:02:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.574 | 49.491 | 21.400 | 11.406 | 12.986 | 30.237 |\n",
      "\u001b[32m[02/23 22:02:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.807  | saturation | 21.500 | artifact   | 16.618 |\n",
      "| blur        | 30.886 | contrast   | 34.969 | bubbles    | 9.784  |\n",
      "| instrument  | 63.982 | blood      | 9.050  |            |        |\n",
      "\u001b[32m[02/23 22:02:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 22:02:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0490 s / img. ETA=0:00:14\n",
      "\u001b[32m[02/23 22:02:15 d2.evaluation.evaluator]: \u001b[0mInference done 100/300. 0.0552 s / img. ETA=0:00:11\n",
      "\u001b[32m[02/23 22:02:20 d2.evaluation.evaluator]: \u001b[0mInference done 188/300. 0.0557 s / img. ETA=0:00:06\n",
      "\u001b[32m[02/23 22:02:25 d2.evaluation.evaluator]: \u001b[0mInference done 276/300. 0.0557 s / img. ETA=0:00:01\n",
      "\u001b[32m[02/23 22:02:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.779533 (0.056880 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:02:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.055558 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:02:26 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 22:02:26 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 22:02:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.98s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.25s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.485\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.053\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.132\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.238\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.432\n",
      "\u001b[32m[02/23 22:02:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 23.749 | 48.473 | 21.633 | 5.320 | 13.195 | 29.338 |\n",
      "\u001b[32m[02/23 22:02:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 10.359 | saturation | 24.057 | artifact   | 16.902 |\n",
      "| blur        | 26.947 | contrast   | 35.100 | bubbles    | 8.166  |\n",
      "| instrument  | 58.190 | blood      | 10.269 |            |        |\n",
      "\u001b[32m[02/23 22:02:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 22:02:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0292 s / img. ETA=0:00:08\n",
      "\u001b[32m[02/23 22:02:38 d2.evaluation.evaluator]: \u001b[0mInference done 184/300. 0.0275 s / img. ETA=0:00:03\n",
      "\u001b[32m[02/23 22:02:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.639561 (0.029287 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:02:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.027411 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:02:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 22:02:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 22:02:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.17s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.20s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.266\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.505\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.150\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.239\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.438\n",
      "\u001b[32m[02/23 22:02:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 26.578 | 50.459 | 24.793 | 4.004 | 15.025 | 32.372 |\n",
      "\u001b[32m[02/23 22:02:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 10.626 | saturation | 21.897 | artifact   | 17.207 |\n",
      "| blur        | 34.642 | contrast   | 37.364 | bubbles    | 10.097 |\n",
      "| instrument  | 65.651 | blood      | 15.143 |            |        |\n",
      "\u001b[32m[02/23 22:02:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 22:02:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0297 s / img. ETA=0:00:08\n",
      "\u001b[32m[02/23 22:02:54 d2.evaluation.evaluator]: \u001b[0mInference done 183/300. 0.0277 s / img. ETA=0:00:03\n",
      "\u001b[32m[02/23 22:02:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.721191 (0.029563 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:02:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.027710 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:02:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 22:02:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 22:02:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.19s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.492\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.322\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.224\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
      "\u001b[32m[02/23 22:03:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 26.187 | 49.226 | 23.530 | 3.986 | 14.242 | 32.199 |\n",
      "\u001b[32m[02/23 22:03:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 10.489 | saturation | 22.221 | artifact   | 17.065 |\n",
      "| blur        | 35.297 | contrast   | 36.504 | bubbles    | 10.035 |\n",
      "| instrument  | 65.876 | blood      | 12.007 |            |        |\n",
      "\u001b[32m[02/23 22:03:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 22:03:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0287 s / img. ETA=0:00:08\n",
      "\u001b[32m[02/23 22:03:10 d2.evaluation.evaluator]: \u001b[0mInference done 184/300. 0.0275 s / img. ETA=0:00:03\n",
      "\u001b[32m[02/23 22:03:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.574714 (0.029067 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:03:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.027406 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:03:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 22:03:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 22:03:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.97s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.19s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.484\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.229\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.139\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.360\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
      "\u001b[32m[02/23 22:03:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 25.575 | 48.424 | 22.853 | 3.666 | 13.900 | 31.718 |\n",
      "\u001b[32m[02/23 22:03:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.984  | saturation | 20.683 | artifact   | 16.595 |\n",
      "| blur        | 34.819 | contrast   | 36.713 | bubbles    | 9.017  |\n",
      "| instrument  | 65.017 | blood      | 11.774 |            |        |\n",
      "\u001b[32m[02/23 22:03:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 22:03:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0288 s / img. ETA=0:00:08\n",
      "\u001b[32m[02/23 22:03:26 d2.evaluation.evaluator]: \u001b[0mInference done 182/300. 0.0278 s / img. ETA=0:00:03\n",
      "\u001b[32m[02/23 22:03:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.735371 (0.029611 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:03:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.027565 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:03:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 22:03:30 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 22:03:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.78s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.18s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.477\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.223\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.137\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.086\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.421\n",
      "\u001b[32m[02/23 22:03:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 24.945 | 47.671 | 22.338 | 4.456 | 13.749 | 31.301 |\n",
      "\u001b[32m[02/23 22:03:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 10.099 | saturation | 20.002 | artifact   | 15.479 |\n",
      "| blur        | 32.360 | contrast   | 36.034 | bubbles    | 9.068  |\n",
      "| instrument  | 63.401 | blood      | 13.116 |            |        |\n",
      "\u001b[32m[02/23 22:03:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 22:03:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0289 s / img. ETA=0:00:08\n",
      "\u001b[32m[02/23 22:03:42 d2.evaluation.evaluator]: \u001b[0mInference done 185/300. 0.0274 s / img. ETA=0:00:03\n",
      "\u001b[32m[02/23 22:03:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.552927 (0.028993 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:03:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.027342 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:03:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 22:03:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 22:03:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.66s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.18s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.245\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.479\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.210\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.086\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.414\n",
      "\u001b[32m[02/23 22:03:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 24.524 | 47.891 | 20.988 | 4.352 | 13.303 | 30.640 |\n",
      "\u001b[32m[02/23 22:03:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.777  | saturation | 18.900 | artifact   | 15.662 |\n",
      "| blur        | 31.113 | contrast   | 35.775 | bubbles    | 9.367  |\n",
      "| instrument  | 64.776 | blood      | 10.824 |            |        |\n",
      "\u001b[32m[02/23 22:03:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 22:03:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0282 s / img. ETA=0:00:08\n",
      "\u001b[32m[02/23 22:03:57 d2.evaluation.evaluator]: \u001b[0mInference done 185/300. 0.0274 s / img. ETA=0:00:03\n",
      "\u001b[32m[02/23 22:04:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.587257 (0.029109 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:04:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.027418 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:04:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 22:04:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 22:04:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.70s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.18s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.245\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.466\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.217\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.043\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.130\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
      "\u001b[32m[02/23 22:04:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 24.499 | 46.641 | 21.693 | 4.285 | 13.004 | 30.615 |\n",
      "\u001b[32m[02/23 22:04:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.439  | saturation | 18.615 | artifact   | 15.248 |\n",
      "| blur        | 32.965 | contrast   | 36.076 | bubbles    | 8.953  |\n",
      "| instrument  | 64.466 | blood      | 10.230 |            |        |\n",
      "\u001b[32m[02/23 22:04:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/23 22:04:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0301 s / img. ETA=0:00:08\n",
      "\u001b[32m[02/23 22:04:13 d2.evaluation.evaluator]: \u001b[0mInference done 184/300. 0.0275 s / img. ETA=0:00:03\n",
      "\u001b[32m[02/23 22:04:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.586757 (0.029108 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:04:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.027490 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/23 22:04:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/23 22:04:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[02/23 22:04:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.63s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.18s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.244\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.464\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.131\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
      "\u001b[32m[02/23 22:04:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 24.368 | 46.404 | 21.765 | 4.208 | 13.064 | 30.588 |\n",
      "\u001b[32m[02/23 22:04:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.580  | saturation | 19.159 | artifact   | 14.865 |\n",
      "| blur        | 32.129 | contrast   | 35.676 | bubbles    | 8.825  |\n",
      "| instrument  | 64.877 | blood      | 9.832  |            |        |\n"
     ]
    }
   ],
   "source": [
    "for checkpoint in checkpoints:\n",
    "    cfg = get_cfg()\n",
    "\n",
    "    cfg.merge_from_file(model_path+\"/config.yaml\")\n",
    "    model = build_model(cfg)\n",
    "    DetectionCheckpointer(model).load(model_path+\"/model_\"+checkpoint+\".pth\")\n",
    "    \n",
    "    evaluator = COCOEvaluator(\"ead_validation_1\", cfg, False, output_dir=\"./output/\")\n",
    "    val_loader = build_detection_test_loader(cfg, \"ead_validation_1\")\n",
    "    a = inference_on_dataset(model, val_loader, evaluator)\n",
    "    \n",
    "    APs.append(a.get('bbox')['AP'])\n",
    "    AP50s.append(a.get('bbox')['AP50'])\n",
    "    AP75s.append(a.get('bbox')['AP75'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd9b0e0d510>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.grid(True)\n",
    "plt.plot(APs)\n",
    "plt.plot(AP50s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23.54148156907953,\n",
       " 25.64902121611055,\n",
       " 25.237210792657745,\n",
       " 24.107917027515178,\n",
       " 25.38522100081583,\n",
       " 26.16867267387023,\n",
       " 25.855799651995337,\n",
       " 25.54757296485809,\n",
       " 24.953006336822135,\n",
       " 24.03716321970156,\n",
       " 23.38537211482386,\n",
       " 24.57448334845891,\n",
       " 23.74874176625008,\n",
       " 26.57833107486939,\n",
       " 26.186728668045095,\n",
       " 25.575208035788343,\n",
       " 24.94493973887077,\n",
       " 24.524188859555156,\n",
       " 24.49907722079604,\n",
       " 24.367781116372772]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[48.48800233215177,\n",
       " 49.92197565093069,\n",
       " 49.909262012634265,\n",
       " 49.03011844763641,\n",
       " 51.35203105722069,\n",
       " 51.15315873967413,\n",
       " 50.7175177552611,\n",
       " 50.6966238516545,\n",
       " 48.903469379665275,\n",
       " 47.123500176273694,\n",
       " 46.22657767061289,\n",
       " 49.4909356676074,\n",
       " 48.47256879917423,\n",
       " 50.45931459854677,\n",
       " 49.22621721331643,\n",
       " 48.424020433251926,\n",
       " 47.670795976203415,\n",
       " 47.89109092357235,\n",
       " 46.641450052802384,\n",
       " 46.404239544957456]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP50s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
