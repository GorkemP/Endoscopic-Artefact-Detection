{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n"
     ]
    }
   ],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from google.colab.patches import cv2_imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metadata(name='ead_validation_1', thing_classes=['specularity', 'saturation', 'artifact', 'blur', 'contrast', 'bubbles', 'instrument', 'blood'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ead_dicts(img_dir):    \n",
    "    images_path = os.path.join(img_dir, '*.jpg')\n",
    "    images = glob.glob(images_path)\n",
    "    \n",
    "    dataset_dicts = []\n",
    "    \n",
    "    for idx, image_path in enumerate(images):\n",
    "        text_path= image_path.replace(\".jpg\", \".txt\")\n",
    "        \n",
    "        record = {}\n",
    "\n",
    "        height, width = cv2.imread(image_path).shape[:2]\n",
    "        \n",
    "        record[\"file_name\"] = image_path\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width        \n",
    "        \n",
    "        with open(text_path) as f:\n",
    "            contents = f.readlines()\n",
    "        \n",
    "        objs = []\n",
    "        for content in contents:\n",
    "            information = content.split(' ')\n",
    "            \n",
    "            obj = {\n",
    "                \"bbox\": [(float(information[1]) - float(information[3]) / 2)*width, \n",
    "                         (float(information[2]) - float(information[4]) / 2)*height, \n",
    "                         (float(information[1]) + float(information[3]) / 2)*width, \n",
    "                         (float(information[2]) + float(information[4]) / 2)*height],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                \"category_id\": int(information[0])\n",
    "            }\n",
    "            objs.append(obj)\n",
    "                        \n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)                        \n",
    "    return dataset_dicts\n",
    "\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "data_path = r'/home/ws2080/Desktop/codes/models/research/ead/data/'\n",
    "train_path = r'/home/ws2080/Desktop/data/training/train/'\n",
    "validation_path = r'/home/ws2080/Desktop/data/training/validation/'\n",
    "\n",
    "'''\n",
    "d= 'train'\n",
    "DatasetCatalog.register(\"ead_train_1\", lambda d=d: get_ead_dicts(train_path))\n",
    "MetadataCatalog.get(\"ead_train_1\").set(thing_classes=[\"specularity\", \"saturation\", \"artifact\", \"blur\", \"contrast\", \"bubbles\", \"instrument\", \"blood\"])\n",
    "\n",
    "'''\n",
    "\n",
    "d= 'validation'\n",
    "DatasetCatalog.register(\"ead_validation_1\", lambda d=d: get_ead_dicts(validation_path))\n",
    "MetadataCatalog.get(\"ead_validation_1\").set(thing_classes=[\"specularity\", \"saturation\", \"artifact\", \"blur\", \"contrast\", \"bubbles\", \"instrument\", \"blood\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'output_24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = ['0009999',\n",
    "               '0019999',\n",
    "               '0029999',\n",
    "               '0039999',\n",
    "               '0049999',\n",
    "               '0059999',\n",
    "               '0069999',    \n",
    "               '0079999',\n",
    "               '0089999',    \n",
    "               '0099999', \n",
    "               '0109999', \n",
    "               '0119999', \n",
    "               '0129999',\n",
    "               '0139999',\n",
    "               '0149999',\n",
    "               '0159999',\n",
    "               '0169999',\n",
    "               '0179999',\n",
    "               '0189999',\n",
    "               '0199999']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checkpoints = ['0199999',\n",
    "               '0209999',\n",
    "               '0219999',\n",
    "               '0229999',\n",
    "               '0239999',\n",
    "               '0249999',\n",
    "               '0259999',\n",
    "               '0269999',\n",
    "               '0279999']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "APs =[]\n",
    "AP50s = []\n",
    "AP75s = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------  0009999  ---------------------------------------------\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/29 11:21:15 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'ead_validation_1'\n",
      "\u001b[32m[02/29 11:21:15 d2.data.datasets.coco]: \u001b[0mCached annotations in COCO format already exist: output_24/ead_validation_1_coco_format.json\n",
      "\u001b[32m[02/29 11:21:16 d2.data.build]: \u001b[0mDistribution of instances among all 8 categories:\n",
      "\u001b[36m|  category   | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:-----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| specularity | 1399         | saturation | 173          |  artifact  | 969          |\n",
      "|    blur     | 96           |  contrast  | 224          |  bubbles   | 622          |\n",
      "| instrument  | 62           |   blood    | 53           |            |              |\n",
      "|    total    | 3598         |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/29 11:21:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:21:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0392 s / img. ETA=0:00:11\n",
      "\u001b[32m[02/29 11:21:22 d2.evaluation.evaluator]: \u001b[0mInference done 134/300. 0.0396 s / img. ETA=0:00:06\n",
      "\u001b[32m[02/29 11:21:27 d2.evaluation.evaluator]: \u001b[0mInference done 256/300. 0.0397 s / img. ETA=0:00:01\n",
      "\u001b[32m[02/29 11:21:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.112911 (0.041061 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:21:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.039640 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:21:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:21:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:21:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=5.57s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.32s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.496\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.229\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.146\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.329\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.254\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.384\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.419\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.267\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498\n",
      "\u001b[32m[02/29 11:21:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 26.015 | 49.616 | 22.876 | 8.675 | 14.612 | 32.941 |\n",
      "\u001b[32m[02/29 11:21:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 7.146  | saturation | 25.220 | artifact   | 19.284 |\n",
      "| blur        | 30.957 | contrast   | 39.126 | bubbles    | 9.877  |\n",
      "| instrument  | 64.916 | blood      | 11.592 |            |        |\n",
      "---------------------------------------  0019999  ---------------------------------------------\n",
      "\u001b[32m[02/29 11:21:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:21:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0408 s / img. ETA=0:00:12\n",
      "\u001b[32m[02/29 11:21:43 d2.evaluation.evaluator]: \u001b[0mInference done 133/300. 0.0402 s / img. ETA=0:00:06\n",
      "\u001b[32m[02/29 11:21:48 d2.evaluation.evaluator]: \u001b[0mInference done 256/300. 0.0400 s / img. ETA=0:00:01\n",
      "\u001b[32m[02/29 11:21:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.229296 (0.041455 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:21:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.040033 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:21:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:21:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:21:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=5.13s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.31s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.280\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.523\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.261\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.092\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.265\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.395\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.428\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.270\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.512\n",
      "\u001b[32m[02/29 11:21:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 27.996 | 52.274 | 26.074 | 9.228 | 16.162 | 34.995 |\n",
      "\u001b[32m[02/29 11:21:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 10.235 | saturation | 27.086 | artifact   | 19.576 |\n",
      "| blur        | 37.504 | contrast   | 40.724 | bubbles    | 11.207 |\n",
      "| instrument  | 63.628 | blood      | 14.011 |            |        |\n",
      "---------------------------------------  0029999  ---------------------------------------------\n",
      "\u001b[32m[02/29 11:22:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:22:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0402 s / img. ETA=0:00:11\n",
      "\u001b[32m[02/29 11:22:06 d2.evaluation.evaluator]: \u001b[0mInference done 133/300. 0.0399 s / img. ETA=0:00:06\n",
      "\u001b[32m[02/29 11:22:11 d2.evaluation.evaluator]: \u001b[0mInference done 256/300. 0.0398 s / img. ETA=0:00:01\n",
      "\u001b[32m[02/29 11:22:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.147204 (0.041177 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:22:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.039815 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:22:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:22:13 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:22:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.97s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.31s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.257\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.485\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.146\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.412\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.271\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.490\n",
      "\u001b[32m[02/29 11:22:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 25.743 | 48.513 | 23.661 | 6.010 | 14.555 | 32.402 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/29 11:22:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.304  | saturation | 26.559 | artifact   | 19.324 |\n",
      "| blur        | 33.779 | contrast   | 37.658 | bubbles    | 10.010 |\n",
      "| instrument  | 59.750 | blood      | 9.560  |            |        |\n",
      "---------------------------------------  0039999  ---------------------------------------------\n",
      "\u001b[32m[02/29 11:22:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:22:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0411 s / img. ETA=0:00:12\n",
      "\u001b[32m[02/29 11:22:30 d2.evaluation.evaluator]: \u001b[0mInference done 133/300. 0.0399 s / img. ETA=0:00:06\n",
      "\u001b[32m[02/29 11:22:35 d2.evaluation.evaluator]: \u001b[0mInference done 255/300. 0.0398 s / img. ETA=0:00:01\n",
      "\u001b[32m[02/29 11:22:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.239542 (0.041490 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:22:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.039805 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:22:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:22:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:22:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.80s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.29s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.265\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.496\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.247\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.408\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.106\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.487\n",
      "\u001b[32m[02/29 11:22:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 26.464 | 49.601 | 23.319 | 4.172 | 14.220 | 33.426 |\n",
      "\u001b[32m[02/29 11:22:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.853  | saturation | 25.369 | artifact   | 19.161 |\n",
      "| blur        | 32.813 | contrast   | 39.786 | bubbles    | 10.250 |\n",
      "| instrument  | 64.340 | blood      | 10.137 |            |        |\n",
      "---------------------------------------  0049999  ---------------------------------------------\n",
      "\u001b[32m[02/29 11:22:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:22:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0398 s / img. ETA=0:00:11\n",
      "\u001b[32m[02/29 11:22:53 d2.evaluation.evaluator]: \u001b[0mInference done 133/300. 0.0399 s / img. ETA=0:00:06\n",
      "\u001b[32m[02/29 11:22:58 d2.evaluation.evaluator]: \u001b[0mInference done 256/300. 0.0398 s / img. ETA=0:00:01\n",
      "\u001b[32m[02/29 11:23:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.160796 (0.041223 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:23:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.039784 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:23:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:23:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:23:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.83s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.28s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.264\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.492\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.241\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.139\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.253\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.405\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.473\n",
      "\u001b[32m[02/29 11:23:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 26.367 | 49.194 | 24.078 | 6.883 | 13.855 | 32.495 |\n",
      "\u001b[32m[02/29 11:23:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 10.221 | saturation | 24.397 | artifact   | 18.563 |\n",
      "| blur        | 37.012 | contrast   | 37.454 | bubbles    | 10.092 |\n",
      "| instrument  | 64.243 | blood      | 8.958  |            |        |\n",
      "---------------------------------------  0059999  ---------------------------------------------\n",
      "\u001b[32m[02/29 11:23:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:23:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0398 s / img. ETA=0:00:11\n",
      "\u001b[32m[02/29 11:23:14 d2.evaluation.evaluator]: \u001b[0mInference done 134/300. 0.0398 s / img. ETA=0:00:06\n",
      "\u001b[32m[02/29 11:23:19 d2.evaluation.evaluator]: \u001b[0mInference done 257/300. 0.0397 s / img. ETA=0:00:01\n",
      "\u001b[32m[02/29 11:23:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.115417 (0.041069 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:23:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.039721 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:23:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:23:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:23:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.85s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.30s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.477\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.096\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.473\n",
      "\u001b[32m[02/29 11:23:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 24.856 | 47.740 | 22.952 | 9.606 | 12.791 | 31.045 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/29 11:23:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 8.958  | saturation | 21.696 | artifact   | 17.658 |\n",
      "| blur        | 33.198 | contrast   | 37.229 | bubbles    | 9.076  |\n",
      "| instrument  | 62.492 | blood      | 8.545  |            |        |\n",
      "---------------------------------------  0069999  ---------------------------------------------\n",
      "\u001b[32m[02/29 11:23:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:23:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0397 s / img. ETA=0:00:11\n",
      "\u001b[32m[02/29 11:23:34 d2.evaluation.evaluator]: \u001b[0mInference done 136/300. 0.0392 s / img. ETA=0:00:06\n",
      "\u001b[32m[02/29 11:23:39 d2.evaluation.evaluator]: \u001b[0mInference done 261/300. 0.0391 s / img. ETA=0:00:01\n",
      "\u001b[32m[02/29 11:23:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.907535 (0.040365 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:23:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.039074 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:23:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:23:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:23:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.89s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.28s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.482\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.110\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.361\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.393\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.241\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.467\n",
      "\u001b[32m[02/29 11:23:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.186 | 48.178 | 23.888 | 11.019 | 13.305 | 31.435 |\n",
      "\u001b[32m[02/29 11:23:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 8.439  | saturation | 23.694 | artifact   | 17.782 |\n",
      "| blur        | 30.380 | contrast   | 35.319 | bubbles    | 10.500 |\n",
      "| instrument  | 66.457 | blood      | 8.921  |            |        |\n",
      "---------------------------------------  0079999  ---------------------------------------------\n",
      "\u001b[32m[02/29 11:23:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:23:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0392 s / img. ETA=0:00:11\n",
      "\u001b[32m[02/29 11:23:55 d2.evaluation.evaluator]: \u001b[0mInference done 135/300. 0.0394 s / img. ETA=0:00:06\n",
      "\u001b[32m[02/29 11:24:00 d2.evaluation.evaluator]: \u001b[0mInference done 258/300. 0.0393 s / img. ETA=0:00:01\n",
      "\u001b[32m[02/29 11:24:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.017208 (0.040736 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:24:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.039279 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:24:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:24:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:24:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.81s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.28s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.473\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.063\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.135\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.311\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.360\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.392\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.129\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.239\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.462\n",
      "\u001b[32m[02/29 11:24:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 25.219 | 47.307 | 23.109 | 6.287 | 13.487 | 31.136 |\n",
      "\u001b[32m[02/29 11:24:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.929  | saturation | 20.201 | artifact   | 16.776 |\n",
      "| blur        | 31.607 | contrast   | 37.122 | bubbles    | 8.899  |\n",
      "| instrument  | 67.550 | blood      | 9.669  |            |        |\n",
      "---------------------------------------  0089999  ---------------------------------------------\n",
      "\u001b[32m[02/29 11:24:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:24:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0404 s / img. ETA=0:00:11\n",
      "\u001b[32m[02/29 11:24:16 d2.evaluation.evaluator]: \u001b[0mInference done 133/300. 0.0400 s / img. ETA=0:00:06\n",
      "\u001b[32m[02/29 11:24:21 d2.evaluation.evaluator]: \u001b[0mInference done 256/300. 0.0398 s / img. ETA=0:00:01\n",
      "\u001b[32m[02/29 11:24:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.112552 (0.041059 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:24:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.039784 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:24:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:24:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:24:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.17s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.26s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.483\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.234\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.130\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.390\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.236\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.455\n",
      "\u001b[32m[02/29 11:24:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 25.958 | 48.342 | 23.417 | 7.924 | 12.999 | 32.765 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/29 11:24:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 10.018 | saturation | 24.042 | artifact   | 16.673 |\n",
      "| blur        | 35.360 | contrast   | 34.771 | bubbles    | 8.069  |\n",
      "| instrument  | 67.468 | blood      | 11.264 |            |        |\n",
      "---------------------------------------  0099999  ---------------------------------------------\n",
      "\u001b[32m[02/29 11:24:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:24:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0398 s / img. ETA=0:00:11\n",
      "\u001b[32m[02/29 11:24:36 d2.evaluation.evaluator]: \u001b[0mInference done 134/300. 0.0397 s / img. ETA=0:00:06\n",
      "\u001b[32m[02/29 11:24:41 d2.evaluation.evaluator]: \u001b[0mInference done 257/300. 0.0397 s / img. ETA=0:00:01\n",
      "\u001b[32m[02/29 11:24:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.093205 (0.040994 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:24:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.039705 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:24:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:24:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:24:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.43s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.27s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.255\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.474\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.127\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.458\n",
      "\u001b[32m[02/29 11:24:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 25.475 | 47.447 | 23.858 | 8.858 | 12.711 | 31.469 |\n",
      "\u001b[32m[02/29 11:24:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 10.113 | saturation | 19.610 | artifact   | 16.524 |\n",
      "| blur        | 34.490 | contrast   | 36.100 | bubbles    | 9.090  |\n",
      "| instrument  | 66.271 | blood      | 11.602 |            |        |\n",
      "---------------------------------------  0109999  ---------------------------------------------\n",
      "\u001b[32m[02/29 11:24:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:24:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0396 s / img. ETA=0:00:11\n",
      "\u001b[32m[02/29 11:24:57 d2.evaluation.evaluator]: \u001b[0mInference done 135/300. 0.0395 s / img. ETA=0:00:06\n",
      "\u001b[32m[02/29 11:25:02 d2.evaluation.evaluator]: \u001b[0mInference done 259/300. 0.0395 s / img. ETA=0:00:01\n",
      "\u001b[32m[02/29 11:25:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.024954 (0.040763 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:25:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.039477 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:25:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:25:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:25:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.49s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.26s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.465\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.138\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.233\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.453\n",
      "\u001b[32m[02/29 11:25:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 23.893 | 46.475 | 21.324 | 4.424 | 13.812 | 30.342 |\n",
      "\u001b[32m[02/29 11:25:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.128  | saturation | 24.864 | artifact   | 17.119 |\n",
      "| blur        | 23.477 | contrast   | 33.220 | bubbles    | 9.744  |\n",
      "| instrument  | 62.644 | blood      | 10.949 |            |        |\n",
      "---------------------------------------  0119999  ---------------------------------------------\n",
      "\u001b[32m[02/29 11:25:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:25:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0394 s / img. ETA=0:00:11\n",
      "\u001b[32m[02/29 11:25:18 d2.evaluation.evaluator]: \u001b[0mInference done 134/300. 0.0396 s / img. ETA=0:00:06\n",
      "\u001b[32m[02/29 11:25:23 d2.evaluation.evaluator]: \u001b[0mInference done 258/300. 0.0395 s / img. ETA=0:00:01\n",
      "\u001b[32m[02/29 11:25:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.015162 (0.040729 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:25:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.039509 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:25:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:25:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:25:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.89s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.25s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.470\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.041\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.136\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.096\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.223\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.446\n",
      "\u001b[32m[02/29 11:25:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 24.562 | 47.005 | 22.404 | 4.138 | 13.558 | 30.185 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/29 11:25:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.561  | saturation | 22.401 | artifact   | 16.639 |\n",
      "| blur        | 31.077 | contrast   | 34.547 | bubbles    | 9.886  |\n",
      "| instrument  | 63.497 | blood      | 8.887  |            |        |\n",
      "---------------------------------------  0129999  ---------------------------------------------\n",
      "\u001b[32m[02/29 11:25:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:25:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0398 s / img. ETA=0:00:11\n",
      "\u001b[32m[02/29 11:25:39 d2.evaluation.evaluator]: \u001b[0mInference done 134/300. 0.0397 s / img. ETA=0:00:06\n",
      "\u001b[32m[02/29 11:25:44 d2.evaluation.evaluator]: \u001b[0mInference done 258/300. 0.0396 s / img. ETA=0:00:01\n",
      "\u001b[32m[02/29 11:25:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.081883 (0.040956 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:25:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.039551 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:25:46 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:25:46 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:25:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.25s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.26s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.470\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.132\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.242\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.347\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.094\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.223\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.452\n",
      "\u001b[32m[02/29 11:25:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 24.740 | 46.991 | 21.771 | 3.543 | 13.183 | 30.999 |\n",
      "\u001b[32m[02/29 11:25:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.114  | saturation | 21.128 | artifact   | 15.589 |\n",
      "| blur        | 33.776 | contrast   | 34.428 | bubbles    | 9.237  |\n",
      "| instrument  | 64.544 | blood      | 10.108 |            |        |\n",
      "---------------------------------------  0139999  ---------------------------------------------\n",
      "\u001b[32m[02/29 11:25:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:25:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0400 s / img. ETA=0:00:11\n",
      "\u001b[32m[02/29 11:25:59 d2.evaluation.evaluator]: \u001b[0mInference done 134/300. 0.0399 s / img. ETA=0:00:06\n",
      "\u001b[32m[02/29 11:26:04 d2.evaluation.evaluator]: \u001b[0mInference done 256/300. 0.0400 s / img. ETA=0:00:01\n",
      "\u001b[32m[02/29 11:26:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.134596 (0.041134 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:26:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.039950 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:26:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:26:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:26:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.20s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.26s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.244\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.469\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.048\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.131\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.236\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.429\n",
      "\u001b[32m[02/29 11:26:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 24.386 | 46.942 | 21.819 | 4.844 | 13.076 | 30.673 |\n",
      "\u001b[32m[02/29 11:26:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.453  | saturation | 24.790 | artifact   | 16.924 |\n",
      "| blur        | 27.295 | contrast   | 33.690 | bubbles    | 9.385  |\n",
      "| instrument  | 63.185 | blood      | 10.368 |            |        |\n",
      "---------------------------------------  0149999  ---------------------------------------------\n",
      "\u001b[32m[02/29 11:26:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0394 s / img. ETA=0:00:14\n",
      "\u001b[32m[02/29 11:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 135/300. 0.0391 s / img. ETA=0:00:06\n",
      "\u001b[32m[02/29 11:26:25 d2.evaluation.evaluator]: \u001b[0mInference done 260/300. 0.0390 s / img. ETA=0:00:01\n",
      "\u001b[32m[02/29 11:26:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.000787 (0.040681 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:26:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.038996 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:26:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:26:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:26:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.51s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.25s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.232\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.441\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.291\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.128\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.424\n",
      "\u001b[32m[02/29 11:26:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 23.250 | 44.082 | 21.825 | 4.401 | 12.629 | 29.126 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/29 11:26:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 7.882  | saturation | 21.700 | artifact   | 15.700 |\n",
      "| blur        | 26.602 | contrast   | 33.388 | bubbles    | 8.650  |\n",
      "| instrument  | 60.866 | blood      | 11.209 |            |        |\n",
      "---------------------------------------  0159999  ---------------------------------------------\n",
      "\u001b[32m[02/29 11:26:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:26:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0404 s / img. ETA=0:00:11\n",
      "\u001b[32m[02/29 11:26:39 d2.evaluation.evaluator]: \u001b[0mInference done 131/300. 0.0406 s / img. ETA=0:00:07\n",
      "\u001b[32m[02/29 11:26:45 d2.evaluation.evaluator]: \u001b[0mInference done 251/300. 0.0406 s / img. ETA=0:00:02\n",
      "\u001b[32m[02/29 11:26:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.365343 (0.041916 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:26:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.040595 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:26:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:26:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:26:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.17s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.19s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.261\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.470\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.047\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.131\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.247\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.092\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.424\n",
      "\u001b[32m[02/29 11:26:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 26.108 | 47.021 | 24.562 | 4.741 | 13.095 | 32.735 |\n",
      "\u001b[32m[02/29 11:26:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.977  | saturation | 22.945 | artifact   | 16.048 |\n",
      "| blur        | 31.993 | contrast   | 37.247 | bubbles    | 9.167  |\n",
      "| instrument  | 67.872 | blood      | 13.609 |            |        |\n",
      "---------------------------------------  0169999  ---------------------------------------------\n",
      "\u001b[32m[02/29 11:26:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:26:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0403 s / img. ETA=0:00:11\n",
      "\u001b[32m[02/29 11:27:01 d2.evaluation.evaluator]: \u001b[0mInference done 131/300. 0.0408 s / img. ETA=0:00:07\n",
      "\u001b[32m[02/29 11:27:06 d2.evaluation.evaluator]: \u001b[0mInference done 253/300. 0.0405 s / img. ETA=0:00:01\n",
      "\u001b[32m[02/29 11:27:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.285599 (0.041646 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:27:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.040459 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:27:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:27:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:27:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.14s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.18s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.466\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.046\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.131\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.090\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.413\n",
      "\u001b[32m[02/29 11:27:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 25.625 | 46.602 | 23.537 | 4.554 | 13.078 | 31.860 |\n",
      "\u001b[32m[02/29 11:27:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.910  | saturation | 21.785 | artifact   | 15.459 |\n",
      "| blur        | 31.196 | contrast   | 37.508 | bubbles    | 8.641  |\n",
      "| instrument  | 66.333 | blood      | 14.166 |            |        |\n",
      "---------------------------------------  0179999  ---------------------------------------------\n",
      "\u001b[32m[02/29 11:27:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:27:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0421 s / img. ETA=0:00:12\n",
      "\u001b[32m[02/29 11:27:23 d2.evaluation.evaluator]: \u001b[0mInference done 131/300. 0.0409 s / img. ETA=0:00:07\n",
      "\u001b[32m[02/29 11:27:28 d2.evaluation.evaluator]: \u001b[0mInference done 251/300. 0.0408 s / img. ETA=0:00:02\n",
      "\u001b[32m[02/29 11:27:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.391896 (0.042006 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:27:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:12 (0.040799 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:27:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:27:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:27:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.91s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.18s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.251\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.468\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.041\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.421\n",
      "\u001b[32m[02/29 11:27:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 25.125 | 46.822 | 23.335 | 4.149 | 12.847 | 31.791 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/29 11:27:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.080  | saturation | 21.802 | artifact   | 14.918 |\n",
      "| blur        | 30.895 | contrast   | 35.654 | bubbles    | 8.380  |\n",
      "| instrument  | 65.923 | blood      | 14.347 |            |        |\n",
      "---------------------------------------  0189999  ---------------------------------------------\n",
      "\u001b[32m[02/29 11:27:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:27:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0405 s / img. ETA=0:00:11\n",
      "\u001b[32m[02/29 11:27:46 d2.evaluation.evaluator]: \u001b[0mInference done 131/300. 0.0407 s / img. ETA=0:00:07\n",
      "\u001b[32m[02/29 11:27:51 d2.evaluation.evaluator]: \u001b[0mInference done 252/300. 0.0406 s / img. ETA=0:00:01\n",
      "\u001b[32m[02/29 11:27:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.323619 (0.041775 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:27:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.040535 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:27:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:27:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:27:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.84s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.19s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.244\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.455\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.223\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.121\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.312\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.240\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.329\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.408\n",
      "\u001b[32m[02/29 11:27:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 24.432 | 45.531 | 22.254 | 4.223 | 12.089 | 31.224 |\n",
      "\u001b[32m[02/29 11:27:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 9.115  | saturation | 20.785 | artifact   | 14.011 |\n",
      "| blur        | 29.536 | contrast   | 35.518 | bubbles    | 8.508  |\n",
      "| instrument  | 64.856 | blood      | 13.128 |            |        |\n",
      "---------------------------------------  0199999  ---------------------------------------------\n",
      "\u001b[32m[02/29 11:27:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 300 images\n",
      "\u001b[32m[02/29 11:27:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/300. 0.0412 s / img. ETA=0:00:12\n",
      "\u001b[32m[02/29 11:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 131/300. 0.0408 s / img. ETA=0:00:07\n",
      "\u001b[32m[02/29 11:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 252/300. 0.0407 s / img. ETA=0:00:02\n",
      "\u001b[32m[02/29 11:28:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.352088 (0.041871 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:28:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.040639 s / img per device, on 1 devices)\n",
      "\u001b[32m[02/29 11:28:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/29 11:28:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_24/coco_instances_results.json\n",
      "\u001b[32m[02/29 11:28:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.76s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.17s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.456\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.242\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.332\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.411\n",
      "\u001b[32m[02/29 11:28:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 24.688 | 45.611 | 22.558 | 4.200 | 12.627 | 31.412 |\n",
      "\u001b[32m[02/29 11:28:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category    | AP     | category   | AP     | category   | AP     |\n",
      "|:------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| specularity | 8.947  | saturation | 21.724 | artifact   | 13.446 |\n",
      "| blur        | 30.663 | contrast   | 35.255 | bubbles    | 8.645  |\n",
      "| instrument  | 65.726 | blood      | 13.097 |            |        |\n"
     ]
    }
   ],
   "source": [
    "for checkpoint in checkpoints:\n",
    "    print('--------------------------------------- ',checkpoint,' ---------------------------------------------')\n",
    "    cfg = get_cfg()\n",
    "\n",
    "    cfg.merge_from_file(model_path+\"/config.yaml\")\n",
    "    model = build_model(cfg)\n",
    "    DetectionCheckpointer(model).load(model_path+\"/model_\"+checkpoint+\".pth\")\n",
    "    \n",
    "    evaluator = COCOEvaluator(\"ead_validation_1\", cfg, False, output_dir=model_path+\"/\")\n",
    "    val_loader = build_detection_test_loader(cfg, \"ead_validation_1\")\n",
    "    a = inference_on_dataset(model, val_loader, evaluator)\n",
    "    \n",
    "    APs.append(a.get('bbox')['AP'])\n",
    "    AP50s.append(a.get('bbox')['AP50'])\n",
    "    AP75s.append(a.get('bbox')['AP75'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa34f67e250>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.grid(True)\n",
    "plt.plot(APs)\n",
    "plt.plot(AP50s)\n",
    "#plt.plot(AP75s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26.014840946635104,\n",
       " 27.9962662038547,\n",
       " 25.742913306294675,\n",
       " 26.463505744975695,\n",
       " 26.36726688735115,\n",
       " 24.85641386469105,\n",
       " 25.186475631613636,\n",
       " 25.219023819256254,\n",
       " 25.958180342926024,\n",
       " 25.474800258994705,\n",
       " 23.893148150644624,\n",
       " 24.56193821678421,\n",
       " 24.740479071086096,\n",
       " 24.386325381502434,\n",
       " 23.249737939740758,\n",
       " 26.10755237670308,\n",
       " 25.624809996134147,\n",
       " 25.124999119651097,\n",
       " 24.432128864140584,\n",
       " 24.687763523010247]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49.61605985507955,\n",
       " 52.27411230941995,\n",
       " 48.51260425031824,\n",
       " 49.60143890327377,\n",
       " 49.1937416724068,\n",
       " 47.73985508673212,\n",
       " 48.177800641075926,\n",
       " 47.306762730126195,\n",
       " 48.34238489011745,\n",
       " 47.44661171570567,\n",
       " 46.47496432196306,\n",
       " 47.00471805562556,\n",
       " 46.99128809562612,\n",
       " 46.94205046329055,\n",
       " 44.08161671623587,\n",
       " 47.02145382847136,\n",
       " 46.6022795749631,\n",
       " 46.82246722997513,\n",
       " 45.53098215527245,\n",
       " 45.611401872645004]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP50s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
