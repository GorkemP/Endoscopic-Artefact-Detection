{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n"
     ]
    }
   ],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "from detectron2.config import get_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detection_bbox  created\n",
      "sequence_bbox  created\n",
      "generalization_bbox  created\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"specularity\", \"saturation\", \"artifact\", \"blur\", \"contrast\", \n",
    "               \"bubbles\", \"instrument\", \"blood\"]\n",
    "\n",
    "# Things to change:\n",
    "# 1: model_path\n",
    "# 2: weights => _009999.pth\n",
    "# 3: SCORE_THRESH_TEST\n",
    "\n",
    "model_path = \"model_cascade_mask_rcnn_R_50_FPN_3x/output_23/\"\n",
    "\n",
    "test_types = ['Detection', 'Detection_sequence', 'Generalization']\n",
    "\n",
    "for test_type in test_types:\n",
    "\n",
    "    test_result_type=''\n",
    "\n",
    "    if test_type == 'Detection':\n",
    "        test_result_type = 'detection_bbox'\n",
    "    elif test_type == 'Detection_sequence':\n",
    "        test_result_type = 'sequence_bbox'\n",
    "    elif test_type == 'Generalization':\n",
    "        test_result_type = 'generalization_bbox'\n",
    "\n",
    "    cfg = get_cfg()\n",
    "\n",
    "    cfg.merge_from_file(model_path+'config.yaml')\n",
    "    cfg.MODEL.WEIGHTS = os.path.join(model_path, \"model_0059999.pth\")\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3   \n",
    "    cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.3\n",
    "    \n",
    "    cfg.DATASETS.TEST = (\"ead_validation_1\",)\n",
    "\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "\n",
    "    VALIDATION_PATH = r'/home/ws2080/Desktop/data/EAD_TEST_FINAL/'+test_type+'/'\n",
    "    TEST_IMAGE_PATHS = glob.glob(VALIDATION_PATH+\"*.jpg\")\n",
    "\n",
    "    for path in TEST_IMAGE_PATHS:\n",
    "        im = cv2.imread(path)\n",
    "        outputs = predictor(im)\n",
    "\n",
    "        txt_home_folder = r'/home/ws2080/Desktop/data/EAD_TEST_FINAL_predictions/'+test_result_type+'/'\n",
    "\n",
    "        txt_file_name = path.split(\"/\")[7]\n",
    "        txt_file_name = txt_file_name.replace(\".jpg\", \".txt\")\n",
    "        txt_file_name = txt_home_folder+txt_file_name    \n",
    "\n",
    "        total_detection = len(outputs[\"instances\"])\n",
    "\n",
    "        temp_detection_list = []\n",
    "        detections = outputs[\"instances\"]\n",
    "\n",
    "        for i in range(total_detection):\n",
    "            temp_detection = class_names[int(detections.pred_classes[i])]+\" \"+ str(float(detections.scores[i]))+\" \"+str(float(detections.pred_boxes.tensor[i,0]))+\" \"+ str(float(detections.pred_boxes.tensor[i,1])) +\" \"+str(float(detections.pred_boxes.tensor[i,2]))+\" \"+ str(float(detections.pred_boxes.tensor[i,3]))\n",
    "            temp_detection_list.append(temp_detection)\n",
    "\n",
    "        with open(txt_file_name, 'w') as f:\n",
    "                for item in temp_detection_list:\n",
    "                    f.write(\"%s\\n\" % item)                                                                           \n",
    "\n",
    "    print(test_result_type, \" created\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
